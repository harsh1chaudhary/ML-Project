{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "33709c12-10ac-46ec-b561-5dcaa87abdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'best_fitness', 'model', 'ema', 'updates', 'optimizer', 'train_args', 'date', 'version'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model_weights = torch.load('A4C_model_seg.pt')\n",
    "\n",
    "# Print the keys of the loaded model to understand its structure\n",
    "print(model_weights.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30c1ba7-b12b-43d5-8d43-db4bfed064a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 40.5ms\n",
      "Speed: 2.8ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 36.7ms\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 39.7ms\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 28.2ms\n",
      "Speed: 1.4ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.3ms\n",
      "Speed: 1.2ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.1ms\n",
      "Speed: 1.1ms preprocess, 25.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 19:32:55.230 python[1136:16397] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-07 19:32:55.230 python[1136:16397] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 person, 1 chair, 27.9ms\n",
      "Speed: 1.2ms preprocess, 27.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 29.1ms\n",
      "Speed: 1.2ms preprocess, 29.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 34.6ms\n",
      "Speed: 1.2ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.1ms\n",
      "Speed: 1.2ms preprocess, 24.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 29.3ms\n",
      "Speed: 1.3ms preprocess, 29.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 26.1ms\n",
      "Speed: 1.1ms preprocess, 26.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.8ms\n",
      "Speed: 1.2ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.2ms\n",
      "Speed: 1.3ms preprocess, 25.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 26.7ms\n",
      "Speed: 1.1ms preprocess, 26.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 29.8ms\n",
      "Speed: 1.2ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.5ms\n",
      "Speed: 1.4ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 28.0ms\n",
      "Speed: 1.2ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.7ms\n",
      "Speed: 1.1ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 28.6ms\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 35.9ms\n",
      "Speed: 1.2ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 28.2ms\n",
      "Speed: 1.3ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 28.8ms\n",
      "Speed: 1.1ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.3ms\n",
      "Speed: 1.1ms preprocess, 27.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.4ms\n",
      "Speed: 1.3ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.9ms\n",
      "Speed: 1.3ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.2ms\n",
      "Speed: 1.2ms preprocess, 27.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 42.6ms\n",
      "Speed: 1.2ms preprocess, 42.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.5ms\n",
      "Speed: 1.2ms preprocess, 23.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.2ms\n",
      "Speed: 1.3ms preprocess, 23.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 39.1ms\n",
      "Speed: 1.3ms preprocess, 39.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.7ms\n",
      "Speed: 1.4ms preprocess, 23.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 26.6ms\n",
      "Speed: 1.4ms preprocess, 26.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.4ms\n",
      "Speed: 1.1ms preprocess, 24.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.4ms\n",
      "Speed: 1.0ms preprocess, 22.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.2ms\n",
      "Speed: 1.1ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.3ms preprocess, 22.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.0ms\n",
      "Speed: 1.2ms preprocess, 21.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.5ms\n",
      "Speed: 1.1ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.0ms\n",
      "Speed: 1.1ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.3ms\n",
      "Speed: 1.1ms preprocess, 22.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 26.6ms\n",
      "Speed: 1.2ms preprocess, 26.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.4ms\n",
      "Speed: 1.3ms preprocess, 22.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.3ms\n",
      "Speed: 1.3ms preprocess, 23.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.9ms\n",
      "Speed: 1.3ms preprocess, 21.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.8ms\n",
      "Speed: 1.2ms preprocess, 21.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.4ms\n",
      "Speed: 1.4ms preprocess, 22.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.4ms\n",
      "Speed: 1.4ms preprocess, 23.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.1ms\n",
      "Speed: 1.1ms preprocess, 22.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 20.9ms\n",
      "Speed: 1.1ms preprocess, 20.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.6ms\n",
      "Speed: 1.1ms preprocess, 21.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.5ms\n",
      "Speed: 1.2ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 20.7ms\n",
      "Speed: 1.1ms preprocess, 20.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.2ms\n",
      "Speed: 1.1ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.7ms\n",
      "Speed: 1.2ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.3ms\n",
      "Speed: 1.4ms preprocess, 21.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.7ms\n",
      "Speed: 1.1ms preprocess, 21.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.5ms\n",
      "Speed: 1.2ms preprocess, 22.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.9ms\n",
      "Speed: 1.1ms preprocess, 21.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.1ms\n",
      "Speed: 1.2ms preprocess, 24.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.9ms\n",
      "Speed: 1.2ms preprocess, 21.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.5ms\n",
      "Speed: 1.1ms preprocess, 23.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.1ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.3ms\n",
      "Speed: 1.2ms preprocess, 21.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.8ms\n",
      "Speed: 1.1ms preprocess, 22.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.9ms\n",
      "Speed: 1.1ms preprocess, 22.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.9ms\n",
      "Speed: 1.4ms preprocess, 22.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.4ms\n",
      "Speed: 1.4ms preprocess, 23.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.0ms\n",
      "Speed: 1.2ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.1ms preprocess, 22.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 20.7ms\n",
      "Speed: 1.1ms preprocess, 20.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.2ms\n",
      "Speed: 1.1ms preprocess, 24.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.6ms\n",
      "Speed: 1.3ms preprocess, 21.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.1ms\n",
      "Speed: 1.9ms preprocess, 23.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.0ms\n",
      "Speed: 1.1ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 tv, 21.6ms\n",
      "Speed: 1.2ms preprocess, 21.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.5ms\n",
      "Speed: 1.1ms preprocess, 22.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.9ms\n",
      "Speed: 1.2ms preprocess, 21.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.5ms\n",
      "Speed: 1.1ms preprocess, 21.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.5ms\n",
      "Speed: 1.3ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.4ms\n",
      "Speed: 1.2ms preprocess, 22.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.9ms\n",
      "Speed: 1.1ms preprocess, 22.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.3ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 50.0ms\n",
      "Speed: 1.5ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.5ms\n",
      "Speed: 1.4ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 29.9ms\n",
      "Speed: 1.2ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.3ms\n",
      "Speed: 1.3ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.5ms\n",
      "Speed: 1.4ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.0ms\n",
      "Speed: 1.3ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.2ms\n",
      "Speed: 1.1ms preprocess, 24.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.7ms\n",
      "Speed: 1.1ms preprocess, 24.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.4ms\n",
      "Speed: 1.1ms preprocess, 24.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.9ms\n",
      "Speed: 1.1ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.9ms\n",
      "Speed: 1.1ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.5ms\n",
      "Speed: 1.3ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.1ms\n",
      "Speed: 1.2ms preprocess, 24.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.5ms\n",
      "Speed: 1.2ms preprocess, 24.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.6ms\n",
      "Speed: 1.1ms preprocess, 23.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.7ms\n",
      "Speed: 1.2ms preprocess, 25.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.4ms\n",
      "Speed: 1.3ms preprocess, 24.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 20.9ms\n",
      "Speed: 1.4ms preprocess, 20.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.3ms\n",
      "Speed: 1.2ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.4ms\n",
      "Speed: 1.2ms preprocess, 23.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 27.2ms\n",
      "Speed: 1.2ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 42.7ms\n",
      "Speed: 1.5ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 29.0ms\n",
      "Speed: 1.2ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.0ms\n",
      "Speed: 1.3ms preprocess, 24.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.7ms\n",
      "Speed: 1.1ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.6ms\n",
      "Speed: 1.2ms preprocess, 24.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.1ms\n",
      "Speed: 1.1ms preprocess, 24.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.9ms\n",
      "Speed: 1.1ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.3ms\n",
      "Speed: 1.3ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.7ms\n",
      "Speed: 1.2ms preprocess, 23.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.2ms\n",
      "Speed: 1.2ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.7ms\n",
      "Speed: 1.3ms preprocess, 24.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 34.9ms\n",
      "Speed: 1.3ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 24.1ms\n",
      "Speed: 1.4ms preprocess, 24.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.5ms\n",
      "Speed: 1.1ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.2ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.4ms\n",
      "Speed: 1.2ms preprocess, 22.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.9ms\n",
      "Speed: 1.2ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.1ms\n",
      "Speed: 1.3ms preprocess, 23.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.7ms\n",
      "Speed: 1.4ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.4ms\n",
      "Speed: 1.2ms preprocess, 23.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 22.6ms\n",
      "Speed: 1.2ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.2ms\n",
      "Speed: 1.2ms preprocess, 23.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 30.6ms\n",
      "Speed: 3.0ms preprocess, 30.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 25.1ms\n",
      "Speed: 1.1ms preprocess, 25.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 21.9ms\n",
      "Speed: 1.1ms preprocess, 21.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 28.0ms\n",
      "Speed: 1.2ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 22.9ms\n",
      "Speed: 1.1ms preprocess, 22.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 chairs, 21.3ms\n",
      "Speed: 1.1ms preprocess, 21.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the pretrained YOLO model (replace 'yolov8n.pt' with your model path if needed)\n",
    "model = YOLO('yolov8n.pt')  # Adjust this if you're using a custom YOLO model\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Loop for real-time object detection\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO object detection on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Initialize counters for humans and objects\n",
    "    human_count = 0\n",
    "    total_objects = 0\n",
    "\n",
    "    # Process each detection result\n",
    "    for result in results:\n",
    "        # Access each bounding box in the result\n",
    "        for box in result.boxes:\n",
    "            # Get the bounding box coordinates, confidence score, and class ID\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())  # Convert to integers\n",
    "            confidence = box.conf[0].item()                  # Convert confidence to float\n",
    "            class_id = int(box.cls[0].item())                # Convert class ID to integer\n",
    "            \n",
    "            # Get the class label and format label text\n",
    "            label = model.names[class_id]\n",
    "            label_text = f\"{label} {confidence:.2f}\"\n",
    "\n",
    "            # Check if the detected object is a human\n",
    "            if label.lower() == 'person':  # Assuming 'person' is the class name for humans\n",
    "                human_count += 1\n",
    "            total_objects += 1\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green bounding box\n",
    "\n",
    "            # Draw the label above the bounding box\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5, (0, 255, 0), 2)  # Green label text\n",
    "\n",
    "    # Display the total counts on the frame\n",
    "    cv2.putText(frame, f'Total Humans: {human_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Total Objects: {total_objects}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Real-time Object Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce64da1-6b00-4770-a49f-440ccf66a081",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "The error you're encountering indicates that the model you're trying to load contains a layer (`DepthwiseConv2D`) that is not recognizing the keyword argument `groups`. This can happen if there is a version mismatch between the Keras model you saved and the Keras (or TensorFlow) version you are currently using to load the model.\n",
    "\n",
    "To fix this error, you can try the following steps:\n",
    "\n",
    "1. **Check TensorFlow/Keras Version**: Ensure that the version of TensorFlow/Keras you are using to load the model matches the version used to create and save the model. You can check your current version with:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06196c45-5153-4e50-bdd4-74bcc1b912c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "   import tensorflow as tf\n",
    "   print(tf.__version__)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba8f6a-a301-452a-8ac2-1295396c456c",
   "metadata": {},
   "source": [
    "\n",
    "2. **Update TensorFlow/Keras**: If there is a version mismatch, consider updating TensorFlow/Keras to the version that was used to create the model. You can do this using pip:\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa30333-694f-4bf6-8906-36139cf0828b",
   "metadata": {},
   "source": [
    "bash\n",
    "   pip install --upgrade tensorflow\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84755b1a-7545-499c-8e7c-00f849912fa2",
   "metadata": {},
   "source": [
    "\n",
    "3. **Modify the Model**: If you have access to the original model code, you can try to modify the model to remove or adjust the `groups` parameter in the `DepthwiseConv2D` layer.\n",
    "\n",
    "Would you like me to provide a code snippet to check your TensorFlow version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "620fb4ea-82d8-4338-ab18-3ee410d066d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18156997-eeba-45ab-956b-550be5b2e95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
