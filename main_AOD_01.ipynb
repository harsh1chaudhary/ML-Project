{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33709c12-10ac-46ec-b561-5dcaa87abdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30c1ba7-b12b-43d5-8d43-db4bfed064a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.3ms\n",
      "Speed: 1.2ms preprocess, 41.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.3ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.9ms\n",
      "Speed: 1.6ms preprocess, 35.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 39.5ms\n",
      "Speed: 2.1ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 45.6ms\n",
      "Speed: 1.3ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 36.1ms\n",
      "Speed: 1.2ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 30.0ms\n",
      "Speed: 1.3ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.5ms\n",
      "Speed: 1.2ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 00:31:48.599 python[2472:690134] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-08 00:31:48.599 python[2472:690134] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 person, 1 bottle, 46.9ms\n",
      "Speed: 1.4ms preprocess, 46.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.6ms\n",
      "Speed: 1.3ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.8ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 31.6ms\n",
      "Speed: 1.3ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 32.3ms\n",
      "Speed: 1.2ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.6ms\n",
      "Speed: 1.3ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.2ms\n",
      "Speed: 1.4ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 27.9ms\n",
      "Speed: 1.3ms preprocess, 27.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.3ms\n",
      "Speed: 1.2ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.8ms\n",
      "Speed: 1.5ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.2ms\n",
      "Speed: 1.1ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.3ms\n",
      "Speed: 1.2ms preprocess, 26.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.1ms\n",
      "Speed: 1.2ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.4ms\n",
      "Speed: 1.2ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.3ms\n",
      "Speed: 1.3ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 26.7ms\n",
      "Speed: 1.2ms preprocess, 26.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.2ms\n",
      "Speed: 1.3ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 26.6ms\n",
      "Speed: 1.3ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.6ms\n",
      "Speed: 1.3ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.8ms\n",
      "Speed: 1.2ms preprocess, 25.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.4ms\n",
      "Speed: 1.2ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.3ms\n",
      "Speed: 1.2ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 30.4ms\n",
      "Speed: 1.2ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 vases, 31.4ms\n",
      "Speed: 1.2ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 27.1ms\n",
      "Speed: 1.2ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 35.8ms\n",
      "Speed: 1.4ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.2ms\n",
      "Speed: 1.3ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.2ms\n",
      "Speed: 1.2ms preprocess, 27.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.8ms\n",
      "Speed: 1.3ms preprocess, 30.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.8ms\n",
      "Speed: 1.3ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.2ms\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.3ms\n",
      "Speed: 1.3ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.2ms\n",
      "Speed: 1.2ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 28.7ms\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.1ms\n",
      "Speed: 1.3ms preprocess, 31.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 27.3ms\n",
      "Speed: 1.2ms preprocess, 27.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 28.2ms\n",
      "Speed: 1.3ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 25.5ms\n",
      "Speed: 1.2ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.2ms\n",
      "Speed: 1.3ms preprocess, 31.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.8ms\n",
      "Speed: 1.3ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 30.7ms\n",
      "Speed: 1.2ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 30.0ms\n",
      "Speed: 1.2ms preprocess, 30.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 26.7ms\n",
      "Speed: 1.1ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.2ms\n",
      "Speed: 1.4ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.5ms\n",
      "Speed: 1.1ms preprocess, 26.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.4ms\n",
      "Speed: 1.3ms preprocess, 30.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.2ms\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.2ms\n",
      "Speed: 1.1ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.8ms\n",
      "Speed: 1.2ms preprocess, 26.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.9ms\n",
      "Speed: 1.2ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.9ms\n",
      "Speed: 1.4ms preprocess, 27.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.4ms\n",
      "Speed: 1.2ms preprocess, 30.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.4ms\n",
      "Speed: 1.2ms preprocess, 28.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.3ms\n",
      "Speed: 1.3ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.0ms\n",
      "Speed: 1.4ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.9ms\n",
      "Speed: 1.2ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.4ms\n",
      "Speed: 1.2ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 29.7ms\n",
      "Speed: 1.2ms preprocess, 29.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.1ms\n",
      "Speed: 1.1ms preprocess, 28.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 29.8ms\n",
      "Speed: 1.3ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 30.2ms\n",
      "Speed: 1.2ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 29.5ms\n",
      "Speed: 1.2ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.3ms\n",
      "Speed: 1.1ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 25.5ms\n",
      "Speed: 1.1ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.5ms\n",
      "Speed: 1.2ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.3ms\n",
      "Speed: 1.4ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 31.5ms\n",
      "Speed: 1.3ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.8ms\n",
      "Speed: 1.2ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 29.0ms\n",
      "Speed: 1.2ms preprocess, 29.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 31.9ms\n",
      "Speed: 1.2ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 43.0ms\n",
      "Speed: 1.2ms preprocess, 43.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 34.0ms\n",
      "Speed: 1.2ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 31.5ms\n",
      "Speed: 1.3ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 30.0ms\n",
      "Speed: 1.3ms preprocess, 30.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.8ms\n",
      "Speed: 1.3ms preprocess, 26.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 32.9ms\n",
      "Speed: 1.3ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.6ms\n",
      "Speed: 1.3ms preprocess, 27.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.6ms\n",
      "Speed: 1.2ms preprocess, 29.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.2ms\n",
      "Speed: 1.2ms preprocess, 26.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.4ms\n",
      "Speed: 1.4ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 31.8ms\n",
      "Speed: 1.4ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.7ms\n",
      "Speed: 1.3ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.5ms\n",
      "Speed: 1.2ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 34.4ms\n",
      "Speed: 1.3ms preprocess, 34.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.9ms\n",
      "Speed: 1.3ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.0ms\n",
      "Speed: 1.3ms preprocess, 28.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.5ms\n",
      "Speed: 1.1ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.1ms\n",
      "Speed: 1.3ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 1 vase, 32.8ms\n",
      "Speed: 1.2ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 32.4ms\n",
      "Speed: 1.4ms preprocess, 32.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.1ms\n",
      "Speed: 1.1ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 30.9ms\n",
      "Speed: 1.1ms preprocess, 30.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Speed: 1.3ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 29.1ms\n",
      "Speed: 1.2ms preprocess, 29.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 30.1ms\n",
      "Speed: 1.1ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.6ms\n",
      "Speed: 1.3ms preprocess, 29.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.9ms\n",
      "Speed: 1.3ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.6ms\n",
      "Speed: 1.2ms preprocess, 27.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.2ms\n",
      "Speed: 1.3ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 23.4ms\n",
      "Speed: 1.1ms preprocess, 23.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 1 vase, 32.3ms\n",
      "Speed: 1.2ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 potted plant, 29.5ms\n",
      "Speed: 1.2ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 30.5ms\n",
      "Speed: 1.2ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 29.3ms\n",
      "Speed: 1.4ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 27.8ms\n",
      "Speed: 1.3ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.6ms\n",
      "Speed: 1.3ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.1ms\n",
      "Speed: 1.2ms preprocess, 27.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.7ms\n",
      "Speed: 1.1ms preprocess, 28.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 26.9ms\n",
      "Speed: 1.4ms preprocess, 26.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 28.4ms\n",
      "Speed: 1.2ms preprocess, 28.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 30.8ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 bottles, 32.5ms\n",
      "Speed: 1.3ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 31.8ms\n",
      "Speed: 1.2ms preprocess, 31.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 30.5ms\n",
      "Speed: 1.2ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 32.6ms\n",
      "Speed: 1.2ms preprocess, 32.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.7ms\n",
      "Speed: 1.2ms preprocess, 31.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 28.0ms\n",
      "Speed: 1.2ms preprocess, 28.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.2ms\n",
      "Speed: 1.2ms preprocess, 28.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 30.8ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.9ms\n",
      "Speed: 1.2ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.7ms\n",
      "Speed: 1.2ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.9ms\n",
      "Speed: 1.2ms preprocess, 28.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 vase, 33.0ms\n",
      "Speed: 1.2ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.4ms\n",
      "Speed: 1.3ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    human_count = 0\n",
    "    total_objects = 0\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            confidence = box.conf[0].item()\n",
    "            class_id = int(box.cls[0].item())\n",
    "\n",
    "            label = model.names[class_id]\n",
    "            label_text = f\"{label} {confidence:.2f}\"\n",
    "\n",
    "            if label.lower() == 'person':\n",
    "                human_count += 1\n",
    "                color = (0, 255, 0)\n",
    "            else:\n",
    "                color = (255, 255, 0)\n",
    "            total_objects += 1\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)\n",
    "\n",
    "    cv2.putText(frame, f'Total Humans: {human_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'Total Objects: {total_objects}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Real-time Object Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce64da1-6b00-4770-a49f-440ccf66a081",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "The error you're encountering indicates that the model you're trying to load contains a layer (`DepthwiseConv2D`) that is not recognizing the keyword argument `groups`. This can happen if there is a version mismatch between the Keras model you saved and the Keras (or TensorFlow) version you are currently using to load the model.\n",
    "\n",
    "To fix this error, you can try the following steps:\n",
    "\n",
    "1. **Check TensorFlow/Keras Version**: Ensure that the version of TensorFlow/Keras you are using to load the model matches the version used to create and save the model. You can check your current version with:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06196c45-5153-4e50-bdd4-74bcc1b912c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "   import tensorflow as tf\n",
    "   print(tf.__version__)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba8f6a-a301-452a-8ac2-1295396c456c",
   "metadata": {},
   "source": [
    "\n",
    "2. **Update TensorFlow/Keras**: If there is a version mismatch, consider updating TensorFlow/Keras to the version that was used to create the model. You can do this using pip:\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa30333-694f-4bf6-8906-36139cf0828b",
   "metadata": {},
   "source": [
    "bash\n",
    "   pip install --upgrade tensorflow\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84755b1a-7545-499c-8e7c-00f849912fa2",
   "metadata": {},
   "source": [
    "\n",
    "3. **Modify the Model**: If you have access to the original model code, you can try to modify the model to remove or adjust the `groups` parameter in the `DepthwiseConv2D` layer.\n",
    "\n",
    "Would you like me to provide a code snippet to check your TensorFlow version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "620fb4ea-82d8-4338-ab18-3ee410d066d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.67.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18156997-eeba-45ab-956b-550be5b2e95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
